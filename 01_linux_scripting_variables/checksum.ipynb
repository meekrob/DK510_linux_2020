{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Exercise\n",
    "\n",
    "Let's apply these constructs to something you can use in a script. We're going to download files from the NCBI directory for the honey bee genome. \n",
    "\n",
    "Navigate to https://ftp.ncbi.nlm.nih.gov/genomes/all/annotation_releases/7460/104/GCF_003254395.2_Amel_HAv3.1 to see a directory listing (clicking will open in a new tab).\n",
    "\n",
    "It looks like:\n",
    "\n",
    "<img src=\"html_dirlisting.png\" alt=\"Directory listing\" style=\"width: 534px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the url in a variable.\n",
    "\n",
    "```BASH\n",
    "\n",
    "baseUrl='https://ftp.ncbi.nlm.nih.gov/genomes/all/annotation_releases/7460/104/GCF_003254395.2_Amel_HAv3.1'\n",
    "\n",
    "```\n",
    "\n",
    "**I'm quoting mine in single quotes** so I don't have to check for things the shell will process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseUrl='https://ftp.ncbi.nlm.nih.gov/genomes/all/annotation_releases/7460/104/GCF_003254395.2_Amel_HAv3.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different files have different data, in a variety of formats. This lecture is more about linux mechanics, so we're just grabbing a small one.\n",
    "\n",
    "Choose by saving one of the file names to a variable called `datafile`. I'm going to use \"GCF_003254395.2_Amel_HAv3.1_genomic.gff.gz\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCF_003254395.2_Amel_HAv3.1_genomic.gff.gz\n",
      "https://ftp.ncbi.nlm.nih.gov/genomes/all/annotation_releases/7460/104/GCF_003254395.2_Amel_HAv3.1/GCF_003254395.2_Amel_HAv3.1_genomic.gff.gz\n"
     ]
    }
   ],
   "source": [
    "datafile=\"GCF_003254395.2_Amel_HAv3.1_genomic.gff.gz\"\n",
    "echo $datafile\n",
    "# fully qualified URL\n",
    "echo $baseUrl/$datafile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have defined the variables correctly, the following command downloads the specified file. This will place a file in your directory with the same name as the string stored in `$datafile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-08-26 17:07:12--  https://ftp.ncbi.nlm.nih.gov/genomes/all/annotation_releases/7460/104/GCF_003254395.2_Amel_HAv3.1/GCF_003254395.2_Amel_HAv3.1_genomic.gff.gz\n",
      "Resolving ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)... 130.14.250.12, 2607:f220:41e:250::11, 2607:f220:41e:250::12, ...\n",
      "Connecting to ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)|130.14.250.12|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6755398 (6.4M) [application/x-gzip]\n",
      "Saving to: ‘GCF_003254395.2_Amel_HAv3.1_genomic.gff.gz’\n",
      "\n",
      "100%[======================================>] 6,755,398   16.5MB/s   in 0.4s   \n",
      "\n",
      "2020-08-26 17:07:14 (16.5 MB/s) - ‘GCF_003254395.2_Amel_HAv3.1_genomic.gff.gz’ saved [6755398/6755398]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wget $baseUrl/$datafile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, get the checksum of the file by running the command `md5sum` on `$datafile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c081b74001f46055b9f5710be2c67f33  GCF_003254395.2_Amel_HAv3.1_genomic.gff.gz\n"
     ]
    }
   ],
   "source": [
    "md5sum $datafile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is md5sum?** It is an algorithm that generates a *cryptographic hash*. This is a signature of the specified file that you can check against an expected number. Using a hash function to check file integrity is called a \"checksum\".\n",
    "\n",
    "**But, how do we check if it's right?**  We need the checksum file. Looking at the directory listing above, the filename is `md5checksums.txt`. Sometimes its called `checksum.txt`, or `checksum.md5` or similar.\n",
    "\n",
    "Set this name, `md5checksums.txt`, to the variable `checksumfile`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checksumfile=md5checksums.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now download the file as you did with `wget $baseUrl/$datafile`, but make use `$checksumfile` instead of `$datafile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-08-26 17:07:24--  https://ftp.ncbi.nlm.nih.gov/genomes/all/annotation_releases/7460/104/GCF_003254395.2_Amel_HAv3.1/md5checksums.txt\n",
      "Resolving ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)... 130.14.250.12, 2607:f220:41e:250::7, 2607:f220:41e:250::12, ...\n",
      "Connecting to ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)|130.14.250.12|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19101 (19K) [text/plain]\n",
      "Saving to: ‘md5checksums.txt’\n",
      "\n",
      "100%[======================================>] 19,101      --.-K/s   in 0.04s   \n",
      "\n",
      "2020-08-26 17:07:25 (433 KB/s) - ‘md5checksums.txt’ saved [19101/19101]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wget $baseUrl/$checksumfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4e40d7b3a70329dee14aeb2f658564ea  ./Annotation_comparison/GCF_003254395.2_Amel_HAv3.1_compare_prev.gbp.gz\n",
      "67a2f793585e04aab9ec5d059b9b4130  ./Annotation_comparison/GCF_003254395.2_Amel_HAv3.1_compare_prev.txt.gz\n",
      "d3b0bf799204e1b34020a1dac1f5686c  ./Evidence_alignments/GCF_003254395.2_Amel_HAv3.1_cross_species_tx_alns.gff.gz\n",
      "390a28099c7478fcb914efbe2cf3a855  ./Evidence_alignments/GCF_003254395.2_Amel_HAv3.1_same_species_tx_alns.gff.gz\n",
      "a8349bcc6a5733d23e5d289dea93e720  ./GCF_003254395.2_Amel_HAv3.1_assembly_report.txt\n",
      "0fad70b254b53b42894b1132a6def686  ./GCF_003254395.2_Amel_HAv3.1_assembly_stats.txt\n",
      "6e1ec842ae5a24ed53a6d866ac613d17  ./GCF_003254395.2_Amel_HAv3.1_assembly_structure/Primary_Assembly/assembled_chromosomes/AGP/chrLG1.agp.gz\n",
      "671eb4b73fa352819654beefe17f465a  ./GCF_003254395.2_Amel_HAv3.1_assembly_structure/Primary_Assembly/assembled_chromosomes/AGP/chrLG1.comp.agp.gz\n",
      "c60d55f350e165e09ce79ec9fbab3851  ./GCF_003254395.2_Amel_HAv3.1_assembly_structure/Primary_Assembly/assembled_chromosomes/AGP/chrLG10.agp.gz\n",
      "7d86b3b706728a346937fdd7f9fad8b1  ./GCF_003254395.2_Amel_HAv3.1_assembly_structure/Primary_Assembly/assembled_chromosomes/AGP/chrLG10.comp.agp.gz\n"
     ]
    }
   ],
   "source": [
    "head $checksumfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Is the checksum right??? How do we tell? There's too much information.\n",
    "\n",
    "Try using `grep` with information you got from the `md5sum` command above. \n",
    "\n",
    "It will take the form `grep PATTERN $checksumfile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c081b74001f46055b9f5710be2c67f33  ./GCF_003254395.2_Amel_HAv3.1_genomic.gff.gz\n"
     ]
    }
   ],
   "source": [
    "grep c081b74001f46055b9f5710be2c67f33 $checksumfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Challenge!** Once you figure out how to get the information with grep, can you run the commands in succession to get a more readable answer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c081b74001f46055b9f5710be2c67f33  GCF_003254395.2_Amel_HAv3.1_genomic.gff.gz\n",
      "c081b74001f46055b9f5710be2c67f33  ./GCF_003254395.2_Amel_HAv3.1_genomic.gff.gz\n"
     ]
    }
   ],
   "source": [
    "# md5sum command\n",
    "md5sum $datafile\n",
    "# grep command\n",
    "grep $datafile $checksumfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did it work? Can you formulate those two commands to use only `$datafile` and `$checksum` as the arguments to the commands?\n",
    "\n",
    "Let's use jupyterlab to convert this notebook into a script.\n",
    "\n",
    "Go to File->Export Notebook As...Export Notebook to Executable Script\n",
    "\n",
    "This will save it to your computer. If you're still figuring out the directory structure, here is the output of my saved script below.\n",
    "```BASH\n",
    "baseUrl='https://ftp.ncbi.nlm.nih.gov/genomes/all/annotation_releases/7460/104/GCF_003254395.2_Amel_HAv3.1'\n",
    "\n",
    "datafile=\"GCF_003254395.2_Amel_HAv3.1_genomic.gff.gz\"\n",
    "echo $datafile\n",
    "# fully qualified URL\n",
    "echo $baseUrl/$datafile\n",
    "\n",
    "wget $baseUrl/$datafile\n",
    "\n",
    "md5sum $datafile\n",
    "\n",
    "checksumfile=md5checksums.txt\n",
    "\n",
    "wget $baseUrl/$checksumfile\n",
    "\n",
    "head $checksumfile\n",
    "\n",
    "grep c081b74001f46055b9f5710be2c67f33 $checksumfile\n",
    "\n",
    "# md5sum command\n",
    "md5sum $datafile\n",
    "# grep command\n",
    "grep $datafile $checksumfile\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's use the script we created from the notebook.\n",
    "\n",
    "---\n",
    "\n",
    "If you can find that exported script on your home computer, then upload it using the up-arrow icon on the JupyterLab icon menu.\n",
    "\n",
    "**Now, switch over to a terminal and make sure you are in our current directory.**\n",
    "\n",
    "You can get the current directory of this notebook via: `pwd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Copy the output from the above command, and paste it after the `cd` command \"*in your terminal*. Remember to leave a space between the `cd` and the pasted text.\n",
    "1. Check to see if you have the script using `ls checksum.sh`\n",
    "1. If not, copy the text from my finished script below:\n",
    "1. Type `nano checksum.sh` *in your terminal*\n",
    "\n",
    "*My fishined script*\n",
    "---\n",
    "```BASH\n",
    "\n",
    "baseUrl='https://ftp.ncbi.nlm.nih.gov/genomes/all/annotation_releases/7460/104/GCF_003254395.2_Amel_HAv3.1'\n",
    "\n",
    "datafile=\"GCF_003254395.2_Amel_HAv3.1_genomic.gff.gz\"\n",
    "echo $datafile\n",
    "# fully qualified URL\n",
    "echo $baseUrl/$datafile\n",
    "\n",
    "wget $baseUrl/$datafile\n",
    "\n",
    "md5sum $datafile\n",
    "\n",
    "checksumfile=md5checksums.txt\n",
    "\n",
    "wget $baseUrl/$checksumfile\n",
    "\n",
    "head $checksumfile\n",
    "\n",
    "grep $datafile $checksumfile\n",
    "\n",
    "# md5sum command\n",
    "md5sum $datafile\n",
    "# grep command\n",
    "grep $datafile $checksumfile\n",
    "\n",
    "```\n",
    "\n",
    "See how we made a script from the jupyter notebook? Do we run it?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
